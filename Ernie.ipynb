{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455e8beb-2bd6-4e38-bb35-c926a22dc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535aa1d5-060c-4fb8-a187-c08129e7fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3769/3599617319.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['text'].fillna(\"Missing text\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"cleaned_data.csv\", encoding='ISO-8859-1')\n",
    "df['text'].fillna(\"Missing text\", inplace=True)\n",
    "\n",
    "# Clean labels\n",
    "valid_labels = ['Left Wing', 'Right Wing', 'Neutral']\n",
    "df['label'] = df['label'].apply(lambda x: x if x in valid_labels else np.nan)\n",
    "df['label'] = df['label'].fillna('Neutral')\n",
    "\n",
    "# Split data\n",
    "train_df, remaining_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(remaining_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "train_df['label'] = encoder.fit_transform(train_df['label'].astype(str))\n",
    "val_df['label'] = encoder.transform(val_df['label'].astype(str))\n",
    "test_df['label'] = encoder.transform(test_df['label'].astype(str))\n",
    "# Check transformed labels\n",
    "print(\"Encoded labels:\", train_df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98839388-5e1a-4b86-a781-b3794df2a99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nghuyong/ernie-1.0')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = self.tokenize_data(df)\n",
    "    \n",
    "    def tokenize_data(self, df):\n",
    "        texts = df['text'].astype(str).tolist()\n",
    "        labels = df['label'].tolist()\n",
    "        \n",
    "        tokenized = self.tokenizer(texts, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "        tokenized['labels'] = torch.tensor(labels, dtype=torch.long)\n",
    "        return tokenized\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.data.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88e9fa4-b89c-42f6-8bb1-078ab2bd5880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of ErnieForSequenceClassification were not initialized from the model checkpoint at nghuyong/ernie-1.0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'nghuyong/ernie-1.0'\n",
    "config = AutoConfig.from_pretrained(model_id, num_labels=3, id2label={0: 'LeftWing', 1: 'Neutral', 2: 'RightWing'})\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3d4621-ce00-4dfe-a766-ed967e169e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0500ad2-deb8-4865-8650-377a25f50603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = TextDataset(train_df)\n",
    "val_dataset = TextDataset(val_df)\n",
    "repository_id = \"harshal-11/Ernie-PoliticalBias-Finetune\"\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591d4d43-205f-4db4-90cf-b70a084aadbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19225' max='19225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19225/19225 17:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.553135</td>\n",
       "      <td>0.760728</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.767947</td>\n",
       "      <td>0.745438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.766200</td>\n",
       "      <td>0.502756</td>\n",
       "      <td>0.794798</td>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.762649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.492800</td>\n",
       "      <td>0.478204</td>\n",
       "      <td>0.802081</td>\n",
       "      <td>0.790782</td>\n",
       "      <td>0.815507</td>\n",
       "      <td>0.777604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.513858</td>\n",
       "      <td>0.817945</td>\n",
       "      <td>0.804287</td>\n",
       "      <td>0.833522</td>\n",
       "      <td>0.787751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.551125</td>\n",
       "      <td>0.821847</td>\n",
       "      <td>0.810301</td>\n",
       "      <td>0.819338</td>\n",
       "      <td>0.803303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19225, training_loss=0.47948870035699814, metrics={'train_runtime': 1038.7102, 'train_samples_per_second': 148.059, 'train_steps_per_second': 18.509, 'total_flos': 2.023210625619456e+16, 'train_loss': 0.47948870035699814, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d526be34-0ae5-4972-bea6-790c0a25cd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='241' max='241' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [241/241 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.47820448875427246,\n",
       " 'eval_accuracy': 0.8020806241872562,\n",
       " 'eval_f1': 0.7907815576095528,\n",
       " 'eval_precision': 0.8155065727351354,\n",
       " 'eval_recall': 0.7776039158713802,\n",
       " 'eval_runtime': 7.0763,\n",
       " 'eval_samples_per_second': 543.366,\n",
       " 'eval_steps_per_second': 34.058,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc12f65f-2c96-4171-9c02-f8fa9ba9aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace 'your_token' with the actual token you copied from Hugging Face.\n",
    "os.environ['HF_TOKEN'] = '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'\n",
    "\n",
    "# Use this environment variable when you create the `Trainer` or call `push_to_hub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b71d9d6-2269-4aca-bb2c-8d4b7dd2086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\n",
      "model.safetensors:   0%|          | 0.00/399M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "training_args.bin:   0%|          | 0.00/4.98k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "training_args.bin: 100%|██████████| 4.98k/4.98k [00:00<00:00, 34.0kB/s][A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   2%|▏         | 9.52M/399M [00:00<00:07, 51.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   4%|▍         | 16.0M/399M [00:00<00:14, 26.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   5%|▌         | 21.5M/399M [00:00<00:11, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   7%|▋         | 26.4M/399M [00:00<00:10, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   8%|▊         | 32.0M/399M [00:01<00:13, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:   9%|▉         | 37.1M/399M [00:01<00:11, 32.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  11%|█         | 42.3M/399M [00:01<00:09, 36.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  12%|█▏        | 47.4M/399M [00:01<00:08, 40.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  13%|█▎        | 52.1M/399M [00:01<00:11, 30.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  14%|█▍        | 57.7M/399M [00:01<00:09, 36.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  16%|█▌        | 62.1M/399M [00:01<00:10, 32.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  17%|█▋        | 65.9M/399M [00:02<00:17, 19.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  18%|█▊        | 70.1M/399M [00:02<00:14, 23.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  19%|█▉        | 75.2M/399M [00:02<00:11, 28.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  20%|██        | 80.0M/399M [00:02<00:12, 26.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  21%|██▏       | 85.3M/399M [00:02<00:09, 31.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  23%|██▎       | 90.6M/399M [00:02<00:08, 36.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  24%|██▍       | 95.5M/399M [00:03<00:07, 39.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  25%|██▌       | 100M/399M [00:03<00:09, 32.3MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  27%|██▋       | 106M/399M [00:03<00:07, 38.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  28%|██▊       | 111M/399M [00:03<00:07, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  29%|██▉       | 115M/399M [00:03<00:09, 28.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  30%|███       | 120M/399M [00:03<00:08, 33.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  31%|███▏      | 125M/399M [00:03<00:07, 37.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  32%|███▏      | 129M/399M [00:04<00:13, 19.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  34%|███▎      | 134M/399M [00:04<00:11, 23.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  35%|███▍      | 140M/399M [00:04<00:08, 29.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  36%|███▌      | 144M/399M [00:04<00:10, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  37%|███▋      | 148M/399M [00:04<00:09, 26.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  38%|███▊      | 152M/399M [00:05<00:08, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  39%|███▉      | 157M/399M [00:05<00:07, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  40%|████      | 161M/399M [00:05<00:09, 24.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  42%|████▏     | 167M/399M [00:05<00:07, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  43%|████▎     | 173M/399M [00:05<00:05, 38.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  45%|████▍     | 178M/399M [00:05<00:06, 34.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  46%|████▌     | 184M/399M [00:05<00:05, 40.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  48%|████▊     | 191M/399M [00:06<00:04, 46.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  49%|████▉     | 196M/399M [00:06<00:06, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  51%|█████     | 203M/399M [00:06<00:05, 38.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  52%|█████▏    | 208M/399M [00:06<00:05, 32.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  54%|█████▍    | 215M/399M [00:06<00:04, 40.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  55%|█████▌    | 222M/399M [00:06<00:03, 45.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  57%|█████▋    | 227M/399M [00:07<00:04, 39.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  58%|█████▊    | 234M/399M [00:07<00:03, 45.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  60%|██████    | 240M/399M [00:07<00:04, 37.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  62%|██████▏   | 247M/399M [00:07<00:03, 44.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  63%|██████▎   | 254M/399M [00:07<00:02, 49.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  65%|██████▍   | 259M/399M [00:07<00:03, 37.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  66%|██████▋   | 266M/399M [00:07<00:03, 43.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  68%|██████▊   | 272M/399M [00:08<00:03, 36.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  70%|██████▉   | 279M/399M [00:08<00:02, 42.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  71%|███████▏  | 285M/399M [00:08<00:02, 47.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  73%|███████▎  | 291M/399M [00:08<00:02, 36.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  74%|███████▍  | 298M/399M [00:08<00:02, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  76%|███████▌  | 304M/399M [00:08<00:02, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  78%|███████▊  | 311M/399M [00:09<00:02, 43.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  79%|███████▉  | 317M/399M [00:09<00:01, 47.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  81%|████████  | 323M/399M [00:09<00:02, 38.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  82%|████████▏ | 329M/399M [00:09<00:01, 43.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  84%|████████▍ | 335M/399M [00:09<00:01, 48.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  85%|████████▌ | 341M/399M [00:09<00:01, 36.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  87%|████████▋ | 347M/399M [00:09<00:01, 42.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  88%|████████▊ | 353M/399M [00:10<00:01, 32.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  90%|████████▉ | 359M/399M [00:10<00:01, 38.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  91%|█████████▏| 365M/399M [00:10<00:00, 42.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  93%|█████████▎| 370M/399M [00:10<00:00, 30.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  94%|█████████▍| 375M/399M [00:10<00:00, 33.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  95%|█████████▍| 379M/399M [00:10<00:00, 35.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  96%|█████████▌| 383M/399M [00:10<00:00, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  97%|█████████▋| 387M/399M [00:11<00:00, 28.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors:  98%|█████████▊| 392M/399M [00:11<00:00, 31.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model.safetensors: 100%|██████████| 399M/399M [00:11<00:00, 34.7MB/s]\u001b[A\u001b[A\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:11<00:00,  5.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/harshal-11/Ernie-PoliticalBias-Finetune/commit/4b79e0021812e91507d7b940bd6fb8b0deb1a010', commit_message='Training completed', commit_description='', oid='4b79e0021812e91507d7b940bd6fb8b0deb1a010', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "trainer.create_model_card()\n",
    "\n",
    "# Push the tokenizer, model, and model card to the hub\n",
    "trainer.push_to_hub(commit_message=\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb440c-bcf1-4082-a1f4-9a219fe8d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eefc22-1e60-4b64-875a-a624eac57db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
